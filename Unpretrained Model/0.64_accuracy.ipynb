{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "5adb039b",
      "metadata": {
        "id": "5adb039b"
      },
      "source": [
        "# Model Klasifikasi Baju Layak dan Tidak Layak Menggunakan CNN Tanpa Pretraining"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras_preprocessing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r44pXA-LAn8b",
        "outputId": "2a621416-612d-4aa6-e122-c93920d69310"
      },
      "id": "r44pXA-LAn8b",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras_preprocessing\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from keras_preprocessing) (1.25.2)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from keras_preprocessing) (1.16.0)\n",
            "Installing collected packages: keras_preprocessing\n",
            "Successfully installed keras_preprocessing-1.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "bf9dcf4a",
      "metadata": {
        "id": "bf9dcf4a"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, Callback\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQrGPdF1AgEQ",
        "outputId": "f94c6aa3-5fce-4f43-cf58-7e05e23c56f1"
      },
      "id": "nQrGPdF1AgEQ",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define paths\n",
        "train_dir = '/content/drive/MyDrive/Bangkit/data_split/train'\n",
        "val_dir = '/content/drive/MyDrive/Bangkit/data_split/val'"
      ],
      "metadata": {
        "id": "d3muqiDMAj0G"
      },
      "id": "d3muqiDMAj0G",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "4fa4390b",
      "metadata": {
        "id": "4fa4390b"
      },
      "source": [
        "## Preprocessing Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "7de3c901",
      "metadata": {
        "id": "7de3c901"
      },
      "outputs": [],
      "source": [
        "def train_val_generators(train_dir, val_dir):\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        rotation_range=40,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest'\n",
        "    )\n",
        "\n",
        "    validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir,\n",
        "        target_size=(256, 256),\n",
        "        batch_size=32,\n",
        "        class_mode='binary'\n",
        "    )\n",
        "\n",
        "    validation_generator = validation_datagen.flow_from_directory(\n",
        "        val_dir,\n",
        "        target_size=(256, 256),\n",
        "        batch_size=32,\n",
        "        class_mode='binary'\n",
        "    )\n",
        "\n",
        "    return train_generator, validation_generator\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator, validation_generator = train_val_generators(train_dir, val_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2uY--muNCjy_",
        "outputId": "986ab22a-d708-46e4-8bba-011ac2edd14d"
      },
      "id": "2uY--muNCjy_",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 812 images belonging to 2 classes.\n",
            "Found 374 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8cb9f89c",
      "metadata": {
        "id": "8cb9f89c"
      },
      "source": [
        "## Membuat Model Tanpa Pretraining"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "ab3d27a1",
      "metadata": {
        "id": "ab3d27a1"
      },
      "outputs": [],
      "source": [
        "    model = Sequential([\n",
        "        Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 3)),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D(2, 2),\n",
        "        Dropout(0.3),\n",
        "\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D(2, 2),\n",
        "        Dropout(0.3),\n",
        "\n",
        "        Conv2D(128, (3, 3), activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D(2, 2),\n",
        "        Dropout(0.3),\n",
        "\n",
        "        Flatten(),\n",
        "        Dense(512, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.5),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    optimizer = Adam(learning_rate=1e-4)  # Set learning rate here\n",
        "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7f47c29",
      "metadata": {
        "id": "e7f47c29"
      },
      "source": [
        "## Melatih Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EarlyStoppingByAccuracy(Callback):\n",
        "    def __init__(self, monitor='val_accuracy', value=0.9, verbose=1):\n",
        "        super(Callback, self).__init__()\n",
        "        self.monitor = monitor\n",
        "        self.value = value\n",
        "        self.verbose = verbose\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        current = logs.get(self.monitor)\n",
        "        if current is None:\n",
        "            print(f\"Early stopping requires {self.monitor} available!\")\n",
        "            return\n",
        "        if current >= self.value:\n",
        "            if self.verbose > 0:\n",
        "                print(f\"Epoch {epoch}: early stopping threshold reached - {self.monitor}: {current}\")\n",
        "            self.model.stop_training = True"
      ],
      "metadata": {
        "id": "qjMYUclRFkkK"
      },
      "id": "qjMYUclRFkkK",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min'),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1, mode='min'),\n",
        "    EarlyStoppingByAccuracy(monitor='val_accuracy', value=0.9, verbose=1)\n",
        "]"
      ],
      "metadata": {
        "id": "Bb9PACjrBRFF"
      },
      "id": "Bb9PACjrBRFF",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "0ce32c06",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ce32c06",
        "outputId": "2a0f9a1d-b52c-41b4-f40d-54ff798b33ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "25/25 [==============================] - 644s 26s/step - loss: 1.0262 - accuracy: 0.6038 - val_loss: 0.8320 - val_accuracy: 0.4545 - lr: 1.0000e-04\n",
            "Epoch 2/50\n",
            "25/25 [==============================] - 19s 757ms/step - loss: 0.7133 - accuracy: 0.6615 - val_loss: 1.7373 - val_accuracy: 0.4631 - lr: 1.0000e-04\n",
            "Epoch 3/50\n",
            "25/25 [==============================] - 19s 742ms/step - loss: 0.6382 - accuracy: 0.6949 - val_loss: 1.7093 - val_accuracy: 0.4489 - lr: 1.0000e-04\n",
            "Epoch 4/50\n",
            "25/25 [==============================] - 18s 716ms/step - loss: 0.6887 - accuracy: 0.6846 - val_loss: 1.5450 - val_accuracy: 0.4602 - lr: 1.0000e-04\n",
            "Epoch 5/50\n",
            "25/25 [==============================] - 20s 784ms/step - loss: 0.7032 - accuracy: 0.6762 - val_loss: 0.8519 - val_accuracy: 0.4602 - lr: 1.0000e-04\n",
            "Epoch 6/50\n",
            "25/25 [==============================] - 19s 766ms/step - loss: 0.6266 - accuracy: 0.7115 - val_loss: 0.6627 - val_accuracy: 0.5966 - lr: 1.0000e-04\n",
            "Epoch 7/50\n",
            "25/25 [==============================] - 18s 722ms/step - loss: 0.6278 - accuracy: 0.6974 - val_loss: 0.6948 - val_accuracy: 0.6165 - lr: 1.0000e-04\n",
            "Epoch 8/50\n",
            "25/25 [==============================] - 20s 809ms/step - loss: 0.6402 - accuracy: 0.7090 - val_loss: 0.7357 - val_accuracy: 0.6165 - lr: 1.0000e-04\n",
            "Epoch 9/50\n",
            "25/25 [==============================] - 18s 717ms/step - loss: 0.6141 - accuracy: 0.7115 - val_loss: 0.9237 - val_accuracy: 0.7017 - lr: 1.0000e-04\n",
            "Epoch 10/50\n",
            "25/25 [==============================] - 19s 772ms/step - loss: 0.5422 - accuracy: 0.7487 - val_loss: 1.4095 - val_accuracy: 0.6222 - lr: 1.0000e-04\n",
            "Epoch 11/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.5386 - accuracy: 0.7359\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
            "25/25 [==============================] - 20s 787ms/step - loss: 0.5386 - accuracy: 0.7359 - val_loss: 1.3540 - val_accuracy: 0.6818 - lr: 1.0000e-04\n",
            "Epoch 12/50\n",
            "25/25 [==============================] - 18s 732ms/step - loss: 0.5762 - accuracy: 0.7462 - val_loss: 1.6698 - val_accuracy: 0.6420 - lr: 1.0000e-05\n",
            "Epoch 13/50\n",
            "25/25 [==============================] - 19s 758ms/step - loss: 0.5675 - accuracy: 0.7256 - val_loss: 1.8323 - val_accuracy: 0.6420 - lr: 1.0000e-05\n",
            "Epoch 14/50\n",
            "25/25 [==============================] - 20s 791ms/step - loss: 0.5452 - accuracy: 0.7679 - val_loss: 2.0639 - val_accuracy: 0.6165 - lr: 1.0000e-05\n",
            "Epoch 15/50\n",
            "25/25 [==============================] - 19s 755ms/step - loss: 0.5426 - accuracy: 0.7295 - val_loss: 2.1314 - val_accuracy: 0.6392 - lr: 1.0000e-05\n",
            "Epoch 16/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.5019 - accuracy: 0.7564\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
            "25/25 [==============================] - 18s 736ms/step - loss: 0.5019 - accuracy: 0.7564 - val_loss: 2.3368 - val_accuracy: 0.6506 - lr: 1.0000e-05\n",
            "Epoch 16: early stopping\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
        "    epochs=50,\n",
        "    callbacks=callbacks\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_model, accuracy_model = model.evaluate(validation_generator, steps=validation_generator.samples // validation_generator.batch_size)\n",
        "print(f\"Model Validation Accuracy: {accuracy_model * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUHmcW1Pb7YW",
        "outputId": "64233e1e-8d75-4614-d6df-58b84ac812ce"
      },
      "id": "AUHmcW1Pb7YW",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11/11 [==============================] - 2s 162ms/step - loss: 2.4193 - accuracy: 0.6420\n",
            "Model Validation Accuracy: 64.20%\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}